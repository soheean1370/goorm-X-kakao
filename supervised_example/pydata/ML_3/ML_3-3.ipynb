{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gwongabjin/Downloads/OneDrive-2025-04-14/pydata\n",
      "       x      y\n",
      "0 -0.753 -0.448\n",
      "1  2.700  0.331\n",
      "2  1.390  0.779\n",
      "3  0.592  0.035\n",
      "4 -2.060 -1.390\n",
      "********\n",
      "(40, 2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "os.chdir(\"../pydata\")\n",
    "print(os.getcwd())\n",
    "\n",
    "dataset = pd.read_csv('wave.csv')\n",
    "print(dataset.head())\n",
    "print(\"********\")\n",
    "print(dataset.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -0.753\n",
      "1    2.700\n",
      "2    1.390\n",
      "3    0.592\n",
      "4   -2.060\n",
      "Name: x, dtype: float64\n",
      "0   -0.448\n",
      "1    0.331\n",
      "2    0.779\n",
      "3    0.035\n",
      "4   -1.390\n",
      "Name: y, dtype: float64\n",
      "********\n",
      "(40,)\n",
      "(40,)\n",
      "********\n",
      "(40, 1)\n"
     ]
    }
   ],
   "source": [
    "X = dataset.iloc[:, 0]\n",
    "y = dataset.iloc[:, 1]\n",
    "\n",
    "print(X.head())\n",
    "print(y.head())\n",
    "print(\"********\")\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(\"********\")\n",
    "X = X.to_frame()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기울기: [0.50209634]\n",
      "절편: -0.03777818977631359\n",
      "훈련 데이터 점수: 0.6968585697022809\n",
      "테스트 데이터 점수: 0.6412244141267605\n",
      "테스트 데이터 점수(반올림): 0.641\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "print(\"기울기:\", lr.coef_)\n",
    "print(\"절편:\", lr.intercept_)\n",
    "\n",
    "print(\"훈련 데이터 점수:\", lr.score(X_train, y_train))\n",
    "print(\"테스트 데이터 점수:\", lr.score(X_test, y_test))\n",
    "print(\"테스트 데이터 점수(반올림):\", round(lr.score(X_test, y_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 1)\n",
      "[1.41830121]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(X_train.shape)\n",
    "\n",
    "X_new = np.array([[2.9]])\n",
    "print(type(X_new))\n",
    "print(X_new.shape)\n",
    "\n",
    "result = lr.predict(X_new)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-1) Ridge Regression 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/pydata'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/pydata\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mgetcwd())\n\u001b[1;32m      8\u001b[0m dataset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/pydata'"
     ]
    }
   ],
   "source": [
    "# L2 규제를 사용하는 릿지 회귀\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "os.chdir(\"C:/pydata\")\n",
    "print(os.getcwd())\n",
    "\n",
    "dataset = pd.read_csv('reg.csv')\n",
    "print(dataset.head())\n",
    "print(dataset.shape)\n",
    "X = dataset.iloc[:, 0:104]\n",
    "y = dataset.iloc[:, 104]\n",
    "\n",
    "print(X.head())\n",
    "print(y.head())\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# X축이 두 개 이상이므로 X축을 2차원으로 만들어주는 작업은 필요없다\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge().fit(X_train, y_train)\n",
    "\n",
    "print(\"기울기:\", ridge.coef_)\n",
    "print(\"절편:\", ridge.intercept_)\n",
    "\n",
    "print(\"훈련 데이터 점수:\", ridge.score(X_train, y_train))\n",
    "print(\"테스트 데이터 점수:\", ridge.score(X_test, y_test))\n",
    "print(\"테스트 데이터 점수(반올림):\", round(ridge.score(X_test, y_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-2) Ridge Regression 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\pydata\n",
      "         x1    x2      x3   x4     x5     x6     x7     x8      x9     x10  \\\n",
      "0  0.000000  0.18  0.0678  0.0  0.315  0.578  0.642  0.269  0.0000  0.2080   \n",
      "1  0.000236  0.00  0.2420  0.0  0.173  0.548  0.783  0.349  0.0435  0.1050   \n",
      "2  0.000236  0.00  0.2420  0.0  0.173  0.694  0.599  0.349  0.0435  0.1050   \n",
      "3  0.000293  0.00  0.0630  0.0  0.150  0.659  0.442  0.449  0.0870  0.0668   \n",
      "4  0.000705  0.00  0.0630  0.0  0.150  0.687  0.528  0.449  0.0870  0.0668   \n",
      "\n",
      "   ...     x96     x97      x98     x99   x100    x101   x102    x103  \\\n",
      "0  ...  0.0597  0.2080  0.01870  0.0825  0.287  0.0258  1.000  0.0897   \n",
      "1  ...  0.0581  0.1050  0.02150  0.3060  0.553  0.1130  1.000  0.2040   \n",
      "2  ...  0.0581  0.1040  0.00666  0.3060  0.548  0.0351  0.980  0.0628   \n",
      "3  ...  0.0433  0.0664  0.00223  0.4210  0.645  0.0217  0.989  0.0332   \n",
      "4  ...  0.0433  0.0668  0.00664  0.4210  0.649  0.0645  1.000  0.0993   \n",
      "\n",
      "      x104     y  \n",
      "0  0.00804  24.0  \n",
      "1  0.04180  21.6  \n",
      "2  0.00403  34.7  \n",
      "3  0.00111  33.4  \n",
      "4  0.00987  36.2  \n",
      "\n",
      "[5 rows x 105 columns]\n",
      "(506, 105)\n",
      "         x1    x2      x3   x4     x5     x6     x7     x8      x9     x10  \\\n",
      "0  0.000000  0.18  0.0678  0.0  0.315  0.578  0.642  0.269  0.0000  0.2080   \n",
      "1  0.000236  0.00  0.2420  0.0  0.173  0.548  0.783  0.349  0.0435  0.1050   \n",
      "2  0.000236  0.00  0.2420  0.0  0.173  0.694  0.599  0.349  0.0435  0.1050   \n",
      "3  0.000293  0.00  0.0630  0.0  0.150  0.659  0.442  0.449  0.0870  0.0668   \n",
      "4  0.000705  0.00  0.0630  0.0  0.150  0.687  0.528  0.449  0.0870  0.0668   \n",
      "\n",
      "   ...      x95     x96     x97      x98     x99   x100    x101   x102  \\\n",
      "0  ...  0.04330  0.0597  0.2080  0.01870  0.0825  0.287  0.0258  1.000   \n",
      "1  ...  0.01100  0.0581  0.1050  0.02150  0.3060  0.553  0.1130  1.000   \n",
      "2  ...  0.01100  0.0581  0.1040  0.00666  0.3060  0.548  0.0351  0.980   \n",
      "3  ...  0.00446  0.0433  0.0664  0.00223  0.4210  0.645  0.0217  0.989   \n",
      "4  ...  0.00446  0.0433  0.0668  0.00664  0.4210  0.649  0.0645  1.000   \n",
      "\n",
      "     x103     x104  \n",
      "0  0.0897  0.00804  \n",
      "1  0.2040  0.04180  \n",
      "2  0.0628  0.00403  \n",
      "3  0.0332  0.00111  \n",
      "4  0.0993  0.00987  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "0    24.0\n",
      "1    21.6\n",
      "2    34.7\n",
      "3    33.4\n",
      "4    36.2\n",
      "Name: y, dtype: float64\n",
      "(506, 104)\n",
      "(506,)\n",
      "기울기: [-8.11611641e-01  6.47282304e-01 -8.06948176e-01  3.11196106e-01\n",
      " -6.85348154e-01  4.38981399e+00 -1.49694871e-01 -2.44234409e+00\n",
      "  8.49320319e-01 -1.14680423e+00 -2.33372393e+00  1.06577949e+00\n",
      " -3.98257101e+00 -5.98928736e-01  2.94377388e-03 -5.20704687e-01\n",
      "  1.40277737e-01 -6.45179618e-01 -7.61099287e-01 -7.48535335e-01\n",
      " -3.85897273e-02 -8.29749501e-01 -7.53038511e-01 -6.74678891e-01\n",
      " -8.71737077e-01 -3.23483442e-01  1.27320901e+00 -3.37326105e-01\n",
      "  6.35226733e-02  2.37335821e-01  2.09712467e+00  1.00564502e-01\n",
      " -2.78695555e-01  1.73785602e-01 -3.33387747e-01 -3.75427350e-01\n",
      "  7.00004953e-01 -6.96727872e-01  7.78599303e-01  3.75286819e-01\n",
      " -6.29053536e-01 -7.61634216e-01  4.38388720e-02 -1.03911226e+00\n",
      "  4.23906306e-01  4.79330796e-01 -3.83488239e-01 -1.00794013e-01\n",
      " -1.30427106e+00  3.11196106e-01 -5.93433342e-01  6.33953785e-01\n",
      "  6.65205296e-01 -1.27688375e-01  1.35320487e+00  1.09764213e+00\n",
      "  6.37900621e-01  4.77212029e-01 -9.71444529e-01 -1.43841969e+00\n",
      " -6.48335960e-02 -9.32097697e-01 -4.55314025e-01 -6.58262940e-01\n",
      " -9.26497750e-01 -1.17143500e+00  3.35576102e-01 -1.76619434e+00\n",
      "  7.02560146e+00  1.51633338e+00  3.92513293e-01 -1.21528896e+00\n",
      " -1.86684987e+00 -1.36269828e+00  5.46209017e+00 -2.89447041e+00\n",
      "  1.27117926e-01 -1.48357718e+00  5.33006240e-01 -4.89716029e-01\n",
      " -1.62371795e+00  6.12944755e-01 -2.98671936e+00 -1.27698528e+00\n",
      " -2.82462015e-01 -1.03491500e+00 -1.69172461e+00 -2.26487010e+00\n",
      " -1.33126479e+00  9.26111620e-01  6.25647222e-01  2.33092054e-01\n",
      "  1.33722674e+00 -1.88262085e+00  3.93107559e-01 -4.45615723e-01\n",
      " -4.54272334e-01 -2.05776669e+00 -1.49611057e+00 -1.77017124e+00\n",
      " -2.03750615e+00  1.08079320e+00 -3.95290266e+00  1.41468286e-01]\n",
      "절편: 25.013639330421874\n",
      "훈련 데이터 점수: 0.7882438442239809\n",
      "테스트 데이터 점수: 0.6359381141518747\n",
      "테스트 데이터 점수(반올림): 0.636\n"
     ]
    }
   ],
   "source": [
    "# L2 규제를 사용하는 릿지 회귀의 alpha값 조절\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "os.chdir(\"C:/pydata\")\n",
    "print(os.getcwd())\n",
    "\n",
    "dataset = pd.read_csv('reg.csv')\n",
    "print(dataset.head())\n",
    "print(dataset.shape)\n",
    "X = dataset.iloc[:, 0:104]\n",
    "y = dataset.iloc[:, 104]\n",
    "\n",
    "print(X.head())\n",
    "print(y.head())\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# X축이 두 개 이상이므로 X축을 2차원으로 만들어주는 작업은 필요없다\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha=10).fit(X_train, y_train)\n",
    "\n",
    "print(\"기울기:\", ridge.coef_)\n",
    "print(\"절편:\", ridge.intercept_)\n",
    "\n",
    "print(\"훈련 데이터 점수:\", ridge.score(X_train, y_train))\n",
    "print(\"테스트 데이터 점수:\", ridge.score(X_test, y_test))\n",
    "print(\"테스트 데이터 점수(반올림):\", round(ridge.score(X_test, y_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-3) Ridge Regression 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "[0.6079900265104548, 0.7723372839728964, 0.7751030513556089, 0.7733999587495815, 0.7707000596584381, 0.7677092719997153, 0.7646506993987046, 0.7616107422047246, 0.7586262385227687, 0.7557131498215399, 0.7528777580552197, 0.7501215796514702, 0.7474437104220942, 0.7448420145385461, 0.742313754153602, 0.7398559326974314, 0.7374654850535007, 0.7351393830309527, 0.7328746927701578, 0.7306686043784759, 0.7285184453561171, 0.7264216845436455, 0.7243759305794291, 0.7223789272599574, 0.7204285472498342, 0.7185227850181001, 0.7166597495294988, 0.7148376570047861, 0.7130548239311568, 0.7113096604211603, 0.7096006639671832, 0.7079264136070501, 0.706285564497241, 0.7046768428791045, 0.703099041417331, 0.7015510148869903, 0.7000316761844578, 0.6985399926377567, 0.697074982592772, 0.6956357122530907, 0.6942212927527306, 0.6928308774425731, 0.6914636593728636, 0.6901188689556272, 0.6887957717922434, 0.6874936666527149, 0.6862118835943753, 0.6849497822088564, 0.6837067499871439, 0.6824822007934482, 0.681275573439444, 0.6800863303511632, 0.6789139563215135, 0.6777579573419905, 0.6766178595077071, 0.6754932079903602, 0.6743835660742099, 0.6732885142505494, 0.6722076493665201, 0.67114058382446, 0.670086944828282, 0.669046373673655, 0.6680185250790165, 0.6670030665546733, 0.6659996778074639, 0.6650080501786382, 0.6640278861127993, 0.6630588986559027, 0.6621008109804576, 0.6611533559362195, 0.6602162756247705, 0.6592893209965158, 0.6583722514687151, 0.6574648345632736, 0.6565668455631001, 0.6556780671859279, 0.6547982892745601, 0.6539273085025825, 0.6530649280946415, 0.6522109575604479, 0.651365212441728, 0.6505275140713822, 0.6496976893441692, 0.6488755704982764, 0.6480609949071701, 0.6472538048811678, 0.6464538474782014, 0.6456609743232781, 0.6448750414361706, 0.644095909066907, 0.6433234415386414, 0.6425575070975275, 0.6417979777692266, 0.6410447292217136, 0.6402976406340559, 0.6395565945708648, 0.6388214768621338, 0.6380921764881936, 0.6373685854695337, 0.636650598761247]\n"
     ]
    }
   ],
   "source": [
    "# 최적의 alpha값 찾기\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pyplot as plt\n",
    "train_accuracy = []                                             # 결과를 받는 빈 리스트\n",
    "test_accuracy = []\n",
    "alphas = np.arange(start=0, stop=10, step=0.1)                 # 0~10까지 0.1 단위로 변경\n",
    "\n",
    "for alpha in alphas:\n",
    "    ridge = Ridge(alpha=alpha).fit(X_train, y_train)           # alpha 값 변경\n",
    "    train_accuracy.append(ridge.score(X_train, y_train))       # 훈련 정확도 저장\n",
    "    test_accuracy.append(ridge.score(X_test, y_test))          # 테스트 정확도 저장\n",
    "    \n",
    "plt.plot(alphas, train_accuracy, label=\"Traing Accuracy\")      # 훈련 정확도\n",
    "plt.plot(alphas, test_accuracy, label=\"Test Accuracy\")         # 테스트 정확도\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(len(test_accuracy))\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-1) Lasso Regression 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\pydata\n",
      "         x1    x2      x3   x4     x5     x6     x7     x8      x9     x10  \\\n",
      "0  0.000000  0.18  0.0678  0.0  0.315  0.578  0.642  0.269  0.0000  0.2080   \n",
      "1  0.000236  0.00  0.2420  0.0  0.173  0.548  0.783  0.349  0.0435  0.1050   \n",
      "2  0.000236  0.00  0.2420  0.0  0.173  0.694  0.599  0.349  0.0435  0.1050   \n",
      "3  0.000293  0.00  0.0630  0.0  0.150  0.659  0.442  0.449  0.0870  0.0668   \n",
      "4  0.000705  0.00  0.0630  0.0  0.150  0.687  0.528  0.449  0.0870  0.0668   \n",
      "\n",
      "   ...     x96     x97      x98     x99   x100    x101   x102    x103  \\\n",
      "0  ...  0.0597  0.2080  0.01870  0.0825  0.287  0.0258  1.000  0.0897   \n",
      "1  ...  0.0581  0.1050  0.02150  0.3060  0.553  0.1130  1.000  0.2040   \n",
      "2  ...  0.0581  0.1040  0.00666  0.3060  0.548  0.0351  0.980  0.0628   \n",
      "3  ...  0.0433  0.0664  0.00223  0.4210  0.645  0.0217  0.989  0.0332   \n",
      "4  ...  0.0433  0.0668  0.00664  0.4210  0.649  0.0645  1.000  0.0993   \n",
      "\n",
      "      x104     y  \n",
      "0  0.00804  24.0  \n",
      "1  0.04180  21.6  \n",
      "2  0.00403  34.7  \n",
      "3  0.00111  33.4  \n",
      "4  0.00987  36.2  \n",
      "\n",
      "[5 rows x 105 columns]\n",
      "(506, 105)\n",
      "         x1    x2      x3   x4     x5     x6     x7     x8      x9     x10  \\\n",
      "0  0.000000  0.18  0.0678  0.0  0.315  0.578  0.642  0.269  0.0000  0.2080   \n",
      "1  0.000236  0.00  0.2420  0.0  0.173  0.548  0.783  0.349  0.0435  0.1050   \n",
      "2  0.000236  0.00  0.2420  0.0  0.173  0.694  0.599  0.349  0.0435  0.1050   \n",
      "3  0.000293  0.00  0.0630  0.0  0.150  0.659  0.442  0.449  0.0870  0.0668   \n",
      "4  0.000705  0.00  0.0630  0.0  0.150  0.687  0.528  0.449  0.0870  0.0668   \n",
      "\n",
      "   ...      x95     x96     x97      x98     x99   x100    x101   x102  \\\n",
      "0  ...  0.04330  0.0597  0.2080  0.01870  0.0825  0.287  0.0258  1.000   \n",
      "1  ...  0.01100  0.0581  0.1050  0.02150  0.3060  0.553  0.1130  1.000   \n",
      "2  ...  0.01100  0.0581  0.1040  0.00666  0.3060  0.548  0.0351  0.980   \n",
      "3  ...  0.00446  0.0433  0.0664  0.00223  0.4210  0.645  0.0217  0.989   \n",
      "4  ...  0.00446  0.0433  0.0668  0.00664  0.4210  0.649  0.0645  1.000   \n",
      "\n",
      "     x103     x104  \n",
      "0  0.0897  0.00804  \n",
      "1  0.2040  0.04180  \n",
      "2  0.0628  0.00403  \n",
      "3  0.0332  0.00111  \n",
      "4  0.0993  0.00987  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "0    24.0\n",
      "1    21.6\n",
      "2    34.7\n",
      "3    33.4\n",
      "4    36.2\n",
      "Name: y, dtype: float64\n",
      "(506, 104)\n",
      "(506,)\n",
      "기울기: [-0.          0.         -0.          0.         -0.          0.\n",
      " -0.          0.         -0.         -0.         -0.          0.\n",
      " -5.34974442 -0.          0.         -0.          0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -0.          0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.          0.          0.          0.         -0.\n",
      " -0.         -0.          0.         -0.         -0.          0.\n",
      " -0.         -1.04778295 -3.31389848 -0.         -0.          0.\n",
      " -0.         -0.         -0.          0.         -0.         -0.41507783\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.         -0.         -0.          0.\n",
      " -0.         -0.        ]\n",
      "절편: 26.124588305143032\n",
      "훈련 데이터 점수: 0.2932077872644062\n",
      "테스트 데이터 점수: 0.20935610983894304\n",
      "테스트 데이터 점수(반올림): 0.209\n"
     ]
    }
   ],
   "source": [
    "# L1 규제를 사용하는 라소 회귀\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "os.chdir(\"C:/pydata\")\n",
    "print(os.getcwd())\n",
    "\n",
    "dataset = pd.read_csv('reg.csv')\n",
    "print(dataset.head())\n",
    "print(dataset.shape)\n",
    "X = dataset.iloc[:, 0:104]\n",
    "y = dataset.iloc[:, 104]\n",
    "\n",
    "print(X.head())\n",
    "print(y.head())\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# X축이 두 개 이상이므로 X축을 2차원으로 만들어주는 작업은 필요없다\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso().fit(X_train, y_train)\n",
    "\n",
    "print(\"기울기:\", lasso.coef_)\n",
    "print(\"절편:\", lasso.intercept_)\n",
    "\n",
    "print(\"훈련 데이터 점수:\", lasso.score(X_train, y_train))\n",
    "print(\"테스트 데이터 점수:\", lasso.score(X_test, y_test))\n",
    "print(\"테스트 데이터 점수(반올림):\", round(lasso.score(X_test, y_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-2) Lasso Regression 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\pydata\n",
      "         x1    x2      x3   x4     x5     x6     x7     x8      x9     x10  \\\n",
      "0  0.000000  0.18  0.0678  0.0  0.315  0.578  0.642  0.269  0.0000  0.2080   \n",
      "1  0.000236  0.00  0.2420  0.0  0.173  0.548  0.783  0.349  0.0435  0.1050   \n",
      "2  0.000236  0.00  0.2420  0.0  0.173  0.694  0.599  0.349  0.0435  0.1050   \n",
      "3  0.000293  0.00  0.0630  0.0  0.150  0.659  0.442  0.449  0.0870  0.0668   \n",
      "4  0.000705  0.00  0.0630  0.0  0.150  0.687  0.528  0.449  0.0870  0.0668   \n",
      "\n",
      "   ...     x96     x97      x98     x99   x100    x101   x102    x103  \\\n",
      "0  ...  0.0597  0.2080  0.01870  0.0825  0.287  0.0258  1.000  0.0897   \n",
      "1  ...  0.0581  0.1050  0.02150  0.3060  0.553  0.1130  1.000  0.2040   \n",
      "2  ...  0.0581  0.1040  0.00666  0.3060  0.548  0.0351  0.980  0.0628   \n",
      "3  ...  0.0433  0.0664  0.00223  0.4210  0.645  0.0217  0.989  0.0332   \n",
      "4  ...  0.0433  0.0668  0.00664  0.4210  0.649  0.0645  1.000  0.0993   \n",
      "\n",
      "      x104     y  \n",
      "0  0.00804  24.0  \n",
      "1  0.04180  21.6  \n",
      "2  0.00403  34.7  \n",
      "3  0.00111  33.4  \n",
      "4  0.00987  36.2  \n",
      "\n",
      "[5 rows x 105 columns]\n",
      "(506, 105)\n",
      "         x1    x2      x3   x4     x5     x6     x7     x8      x9     x10  \\\n",
      "0  0.000000  0.18  0.0678  0.0  0.315  0.578  0.642  0.269  0.0000  0.2080   \n",
      "1  0.000236  0.00  0.2420  0.0  0.173  0.548  0.783  0.349  0.0435  0.1050   \n",
      "2  0.000236  0.00  0.2420  0.0  0.173  0.694  0.599  0.349  0.0435  0.1050   \n",
      "3  0.000293  0.00  0.0630  0.0  0.150  0.659  0.442  0.449  0.0870  0.0668   \n",
      "4  0.000705  0.00  0.0630  0.0  0.150  0.687  0.528  0.449  0.0870  0.0668   \n",
      "\n",
      "   ...      x95     x96     x97      x98     x99   x100    x101   x102  \\\n",
      "0  ...  0.04330  0.0597  0.2080  0.01870  0.0825  0.287  0.0258  1.000   \n",
      "1  ...  0.01100  0.0581  0.1050  0.02150  0.3060  0.553  0.1130  1.000   \n",
      "2  ...  0.01100  0.0581  0.1040  0.00666  0.3060  0.548  0.0351  0.980   \n",
      "3  ...  0.00446  0.0433  0.0664  0.00223  0.4210  0.645  0.0217  0.989   \n",
      "4  ...  0.00446  0.0433  0.0668  0.00664  0.4210  0.649  0.0645  1.000   \n",
      "\n",
      "     x103     x104  \n",
      "0  0.0897  0.00804  \n",
      "1  0.2040  0.04180  \n",
      "2  0.0628  0.00403  \n",
      "3  0.0332  0.00111  \n",
      "4  0.0993  0.00987  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "0    24.0\n",
      "1    21.6\n",
      "2    34.7\n",
      "3    33.4\n",
      "4    36.2\n",
      "Name: y, dtype: float64\n",
      "(506, 104)\n",
      "(506,)\n",
      "기울기: [ -0.           0.          -0.           0.          -0.\n",
      "   0.          -0.          -0.          -0.          -0.\n",
      "  -6.95083014   0.         -15.73573698  -0.           0.\n",
      "  -0.           0.          -0.          -0.          -0.\n",
      "  -0.          -0.          -0.          -0.          -0.\n",
      "  -0.           0.          -0.           0.           0.\n",
      "   0.           0.          -0.           0.          -0.\n",
      "  -0.           0.          -0.          -0.           0.\n",
      "  -0.          -0.          -0.          -0.          -0.\n",
      "  -0.          -0.          -0.          -0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           1.57120477   0.          -0.07304405\n",
      "  -0.          -0.          -0.          -0.          -0.\n",
      "  -0.          -0.          -0.          19.43643796  -0.\n",
      "  -0.          -0.          -5.12234385  -0.           5.33437192\n",
      "  -0.          -0.          -0.          -0.          -0.\n",
      "  -0.           0.          -0.45983666  -0.          -0.\n",
      "  -0.          -0.          -0.          -0.          -0.\n",
      "  -0.          -0.           0.          -0.          -0.\n",
      "  -0.          -0.          -0.          -0.          -0.\n",
      "  -0.           0.          -0.           0.        ]\n",
      "절편: 24.429882518603655\n",
      "훈련 데이터 점수: 0.77094949101076\n",
      "테스트 데이터 점수: 0.6303135818440677\n",
      "테스트 데이터 점수(반올림): 0.63\n"
     ]
    }
   ],
   "source": [
    "# alpha 값을 줄인 라소 회귀\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "os.chdir(\"C:/pydata\")\n",
    "print(os.getcwd())\n",
    "\n",
    "dataset = pd.read_csv('reg.csv')\n",
    "print(dataset.head())\n",
    "print(dataset.shape)\n",
    "X = dataset.iloc[:, 0:104]\n",
    "y = dataset.iloc[:, 104]\n",
    "\n",
    "print(X.head())\n",
    "print(y.head())\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# X축이 두 개 이상이므로 X축을 2차원으로 만들어주는 작업은 필요없다\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(alpha=0.1).fit(X_train, y_train)\n",
    "\n",
    "print(\"기울기:\", lasso.coef_)\n",
    "print(\"절편:\", lasso.intercept_)\n",
    "\n",
    "print(\"훈련 데이터 점수:\", lasso.score(X_train, y_train))\n",
    "print(\"테스트 데이터 점수:\", lasso.score(X_test, y_test))\n",
    "print(\"테스트 데이터 점수(반올림):\", round(lasso.score(X_test, y_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\pydata\n",
      "         x1    x2      x3   x4     x5     x6     x7     x8      x9     x10  \\\n",
      "0  0.000000  0.18  0.0678  0.0  0.315  0.578  0.642  0.269  0.0000  0.2080   \n",
      "1  0.000236  0.00  0.2420  0.0  0.173  0.548  0.783  0.349  0.0435  0.1050   \n",
      "2  0.000236  0.00  0.2420  0.0  0.173  0.694  0.599  0.349  0.0435  0.1050   \n",
      "3  0.000293  0.00  0.0630  0.0  0.150  0.659  0.442  0.449  0.0870  0.0668   \n",
      "4  0.000705  0.00  0.0630  0.0  0.150  0.687  0.528  0.449  0.0870  0.0668   \n",
      "\n",
      "   ...     x96     x97      x98     x99   x100    x101   x102    x103  \\\n",
      "0  ...  0.0597  0.2080  0.01870  0.0825  0.287  0.0258  1.000  0.0897   \n",
      "1  ...  0.0581  0.1050  0.02150  0.3060  0.553  0.1130  1.000  0.2040   \n",
      "2  ...  0.0581  0.1040  0.00666  0.3060  0.548  0.0351  0.980  0.0628   \n",
      "3  ...  0.0433  0.0664  0.00223  0.4210  0.645  0.0217  0.989  0.0332   \n",
      "4  ...  0.0433  0.0668  0.00664  0.4210  0.649  0.0645  1.000  0.0993   \n",
      "\n",
      "      x104     y  \n",
      "0  0.00804  24.0  \n",
      "1  0.04180  21.6  \n",
      "2  0.00403  34.7  \n",
      "3  0.00111  33.4  \n",
      "4  0.00987  36.2  \n",
      "\n",
      "[5 rows x 105 columns]\n",
      "(506, 105)\n",
      "         x1    x2      x3   x4     x5     x6     x7     x8      x9     x10  \\\n",
      "0  0.000000  0.18  0.0678  0.0  0.315  0.578  0.642  0.269  0.0000  0.2080   \n",
      "1  0.000236  0.00  0.2420  0.0  0.173  0.548  0.783  0.349  0.0435  0.1050   \n",
      "2  0.000236  0.00  0.2420  0.0  0.173  0.694  0.599  0.349  0.0435  0.1050   \n",
      "3  0.000293  0.00  0.0630  0.0  0.150  0.659  0.442  0.449  0.0870  0.0668   \n",
      "4  0.000705  0.00  0.0630  0.0  0.150  0.687  0.528  0.449  0.0870  0.0668   \n",
      "\n",
      "   ...      x95     x96     x97      x98     x99   x100    x101   x102  \\\n",
      "0  ...  0.04330  0.0597  0.2080  0.01870  0.0825  0.287  0.0258  1.000   \n",
      "1  ...  0.01100  0.0581  0.1050  0.02150  0.3060  0.553  0.1130  1.000   \n",
      "2  ...  0.01100  0.0581  0.1040  0.00666  0.3060  0.548  0.0351  0.980   \n",
      "3  ...  0.00446  0.0433  0.0664  0.00223  0.4210  0.645  0.0217  0.989   \n",
      "4  ...  0.00446  0.0433  0.0668  0.00664  0.4210  0.649  0.0645  1.000   \n",
      "\n",
      "     x103     x104  \n",
      "0  0.0897  0.00804  \n",
      "1  0.2040  0.04180  \n",
      "2  0.0628  0.00403  \n",
      "3  0.0332  0.00111  \n",
      "4  0.0993  0.00987  \n",
      "\n",
      "[5 rows x 104 columns]\n",
      "0    24.0\n",
      "1    21.6\n",
      "2    34.7\n",
      "3    33.4\n",
      "4    36.2\n",
      "Name: y, dtype: float64\n",
      "(506, 104)\n",
      "(506,)\n",
      "기울기: [-0.19480355  0.59703997 -0.70043415  0.47576528 -0.30785599  2.03662812\n",
      " -0.17895256 -0.46627126 -0.         -0.65026627 -1.74005817  0.71783872\n",
      " -2.31599609 -0.01574064  0.         -0.03801352  0.         -0.05790052\n",
      " -0.         -0.17034686 -0.         -0.18891316 -0.15398037 -0.11666287\n",
      " -0.07402431 -0.04656882  0.47423538  0.          0.          0.\n",
      "  0.75756148  0.08156701  0.          0.          0.         -0.\n",
      "  0.60570858 -0.         -0.20507638  0.15537725 -0.43153743 -0.\n",
      " -0.51603428 -0.05921397 -0.         -0.20085601 -0.65349389 -0.08910022\n",
      " -1.05479819  0.47577133  0.          0.44360024  0.35408916  0.\n",
      "  0.46077679  0.38016041  0.27806953  0.46631377 -0.         -0.48759397\n",
      "  0.07985315 -0.40116062 -0.         -0.15495952 -0.40054807 -0.6530377\n",
      "  0.         -1.01003933  2.75047365  0.90640916  0.          0.\n",
      " -0.         -0.09745289  2.52411146 -0.81458213 -0.34874096 -0.2206867\n",
      " -0.0097526  -0.52545548 -1.35417756  0.16420442 -1.91099693 -0.29976577\n",
      " -0.         -0.06126968 -0.61951546 -0.34607177 -0.32395998 -0.\n",
      " -0.02002565 -0.19296351  0.32528372 -0.93111523 -0.24673386 -0.64436383\n",
      " -0.         -1.16839074 -1.64198783 -1.00669503 -1.61396117  0.87358639\n",
      " -1.77592886 -1.07789946]\n",
      "절편: 25.827439020180126\n",
      "훈련 데이터 점수: 0.6336737631832918\n",
      "테스트 데이터 점수: 0.45394319395300403\n",
      "테스트 데이터 점수(반올림): 0.454\n"
     ]
    }
   ],
   "source": [
    "# 릿지와 라소를 혼합한 엘라스틱넷\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "os.chdir(\"C:/pydata\")\n",
    "print(os.getcwd())\n",
    "\n",
    "dataset = pd.read_csv('reg.csv')\n",
    "print(dataset.head())\n",
    "print(dataset.shape)\n",
    "X = dataset.iloc[:, 0:104]\n",
    "y = dataset.iloc[:, 104]\n",
    "\n",
    "print(X.head())\n",
    "print(y.head())\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# X축이 두 개 이상이므로 X축을 2차원으로 만들어주는 작업은 필요없다\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "elasticnet = ElasticNet(alpha=0.2, l1_ratio=0.2).fit(X_train, y_train)\n",
    "\n",
    "print(\"기울기:\", elasticnet.coef_)\n",
    "print(\"절편:\", elasticnet.intercept_)\n",
    "\n",
    "print(\"훈련 데이터 점수:\", elasticnet.score(X_train, y_train))\n",
    "print(\"테스트 데이터 점수:\", elasticnet.score(X_test, y_test))\n",
    "print(\"테스트 데이터 점수(반올림):\", round(elasticnet.score(X_test, y_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
